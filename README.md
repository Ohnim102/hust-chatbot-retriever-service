# Retriever service


## üìã Overview

API n√†y cung c·∫•p c√°c ch·ª©c nƒÉng cho h·ªá th·ªëng Retrieval-Augmented Generation (RAG), bao g·ªìm:
- Upload t√†i li·ªáu v√†o VectorDB
- Truy v·∫•n t√†i li·ªáu
- Sinh prompt cho LLM
- X√≥a t√†i li·ªáu theo doc_id
- Xo√° t√†i li·ªáu ho·∫∑c to√†n b·ªô VectorDB

Retriever service:
- Base URL: `http://localhost:8081/api/`  
- Swagger: `http://localhost:8081/docs`

Qdrant DB: `http://localhost:6333/dashboard#/collections`  
Chroma DB: `http://127.0.0.1:8000/docs/`

## üöÄ Deploy

```sh
# build image
docker build -t retriever-service .

# run
docker compose up -d

# pull ollama model
docker exec ollama ollama pull nomic-embed-text

# docker exec ollama ollama pull deepseek-r1:8b
```

### C·∫•u tr√∫c project:
```
retriever-chromadb/
‚îú‚îÄ .venv/
‚îú‚îÄ .vscode/
‚îÇ  ‚îú‚îÄ launch.json
‚îÇ  ‚îî‚îÄ settings.json
‚îú‚îÄ requirements.txt
‚îú‚îÄ retriever_service.py
‚îú‚îÄ ingest.py
‚îú‚îÄ utils.py
‚îú‚îÄ Dockerfile
‚îî‚îÄ docker-compose.yml
```

## Installation
C√†i ƒë·∫∑t th∆∞ vi·ªán
```python
python -m venv .venv
.venv\Scripts\activate
pip install -r requirements.txt 
```

Run Ollama v√† Qdrant
```sh
docker compose run ollama
docker compose run qdrant
```

ssh v√†o container Ollama
```sh
ollama pull nomic-embed-text
ollama pull deepseek-r1:8b  # Option
```


## üß© API Endpoints

### 1. Upload Document for RAG

Upload t√†i li·ªáu ƒë·ªÉ ƒë∆∞a v√†o h·ªá th·ªëng RAG.

**Endpoint**: `POST /api/rag/upload-for-rag`

**Tags**: `rag`

**Request Body** (multipart/form-data):

| Field | Type | Required | Default | Description |
|-------|------|----------|---------|-------------|
| `doc_id` | string | ‚úÖ | - | ID ƒë·ªãnh danh cho t√†i li·ªáu |
| `file` | binary | ‚úÖ | - | File t√†i li·ªáu c·∫ßn upload |
| `collection` | string | ‚ùå | `rag_collection` | T√™n collection ƒë·ªÉ l∆∞u tr·ªØ (`rag_collection` ho·∫∑c `search_collection`) |

**Response**:
- `200`: Upload th√†nh c√¥ng
- `422`: L·ªói validation

**Example cURL**:
```bash
curl -X POST "http://api.example.com/api/rag/upload-for-rag" \
  -F "doc_id=doc123" \
  -F "file=@document.pdf" \
  -F "collection=rag_collection"
```

**Example Response**:
  `"./temp_uploads\\H√† N·ªôi.pdf"`

---

### 2. Delete Document by ID

X√≥a t√†i li·ªáu kh·ªèi vector database theo doc_id.

**Endpoint**: `DELETE /api/rag/delete-document-by-doc-id`

**Tags**: `rag`

**Query Parameters**:

| Parameter | Type | Required | Default | Description |
|-----------|------|----------|---------|-------------|
| `doc_id` | string | ‚úÖ | - | ID c·ªßa t√†i li·ªáu c·∫ßn x√≥a |
| `collection` | string | ‚ùå | `rag_collection` | T√™n collection ch·ª©a t√†i li·ªáu |

**Response**:
- `200`: X√≥a th√†nh c√¥ng
- `422`: L·ªói validation

**Example cURL**:
```bash
curl -X DELETE "http://api.example.com/api/rag/delete-document-by-doc-id?doc_id=doc123&collection=rag_collection"
```

**Example Response**:
```json
{
  "success": true,
  "doc_id": "987654321"
}
```
---

### 3. Query Document

T√¨m ki·∫øm t√†i li·ªáu trong vector database.

**Endpoint**: `GET /api/rag/query`

**Tags**: `rag`

**Query Parameters**:

| Parameter | Type | Required | Default | Description |
|-----------|------|----------|---------|-------------|
| `query` | string | ‚úÖ | - | C√¢u truy v·∫•n t√¨m ki·∫øm |
| `k` | integer | ‚úÖ | - | S·ªë l∆∞·ª£ng k·∫øt qu·∫£ tr·∫£ v·ªÅ |
| `collection` | string | ‚ùå | `rag_collection` | T√™n collection ƒë·ªÉ t√¨m ki·∫øm |

**Response**:
- `200`: Tr·∫£ v·ªÅ k·∫øt qu·∫£ t√¨m ki·∫øm
- `422`: L·ªói validation

**Example cURL**:
```bash
curl -X GET "http://api.example.com/api/rag/query?query=machine%20learning&k=5&collection=rag_collection"
```

**Example Response**:
```json
[
    {
        "source": "./temp_uploads\\Vincom Landmark 81.docx",
        "metadata": {
            "source": "./temp_uploads\\Vincom Landmark 81.docx",
            "total_pages": 0,
            "creationdate": "",
            "title": "Untitled",
            "author": "Unknown Author"
        },
        "matches": [
            {
                "page_content": "Ri√™ng t·∫ßng 21. 46H v√† 78 l√† t·∫ßng kƒ© thu·∫≠t.",
                "score": 0.75985098,
                "page": 0
            },
            {
                "page_content": "T√™n file: Vincom Landmark 81.docx",
                "score": 0.674089315,
                "page": 0
            }
        ]
    }
]
```

---

### 4. Generate Prompt

T·∫°o prompt d·ª±a tr√™n c√¢u truy v·∫•n v√† context t·ª´ vector database.

**Endpoint**: `GET /api/rag/generate-prompt`

**Tags**: `rag`

**Query Parameters**:

| Parameter | Type | Required | Default | Description |
|-----------|------|----------|---------|-------------|
| `query` | string | ‚úÖ | - | C√¢u truy v·∫•n |
| `collection` | string | ‚ùå | `rag_collection` | T√™n collection ƒë·ªÉ l·∫•y context |

**Response**:
- `200`: Tr·∫£ v·ªÅ prompt ƒë√£ ƒë∆∞·ª£c t·∫°o
- `422`: L·ªói validation

**Example cURL**:
```bash
curl -X GET "http://api.example.com/api/rag/generate-prompt?query=what%20is%20AI&collection=rag_collection"
```

---

### 5. Clear Vector Database

X√≥a to√†n b·ªô d·ªØ li·ªáu trong m·ªôt collection.

**Endpoint**: `GET /api/rag/clear-vectordb`

**Tags**: `rag`

**Query Parameters**:

| Parameter | Type | Required | Default | Description |
|-----------|------|----------|---------|-------------|
| `collection` | string | ‚úÖ | - | T√™n collection c·∫ßn x√≥a (`rag_collection` ho·∫∑c `search_collection`) |

**Response**:
- `200`: X√≥a th√†nh c√¥ng
- `422`: L·ªói validation

**Example cURL**:
```bash
curl -X GET "http://api.example.com/api/rag/clear-vectordb?collection=rag_collection"
```

---

## Ollama Endpoints

### 6. Chat Stream

G·ª≠i request chat ƒë·∫øn Ollama v·ªõi kh·∫£ nƒÉng streaming response.

**Endpoint**: `POST /api/ollama/chat/stream`

**Tags**: `ollama`

**Request Body** (application/json):

| Field | Type | Required | Default | Description |
|-------|------|----------|---------|-------------|
| `model` | string | ‚úÖ | - | T√™n model Ollama s·ª≠ d·ª•ng |
| `messages` | array | ‚úÖ | - | Danh s√°ch c√°c message trong cu·ªôc h·ªôi tho·∫°i |
| `chat_id` | integer/null | ‚ùå | `null` | ID c·ªßa chat session |
| `options` | object/null | ‚ùå | `null` | C√°c t√πy ch·ªçn b·ªï sung cho model |
| `streaming` | boolean/null | ‚ùå | `true` | B·∫≠t/t·∫Øt streaming response |

**Request Body Example**:
```json
{
  "model": "llama2",
  "messages": [
    {
      "role": "system",
      "content": "You are a helpful assistant."
    },
    {
      "role": "user",
      "content": "What is machine learning?"
    }
  ],
  "chat_id": 123,
  "options": {
    "temperature": 0.7,
    "top_p": 0.9
  },
  "streaming": true
}
```

**Response**:
- `200`: Tr·∫£ v·ªÅ response t·ª´ Ollama (streaming ho·∫∑c non-streaming)
- `422`: L·ªói validation

**Example cURL**:
```bash
curl -X POST "http://api.example.com/api/ollama/chat/stream" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "llama2",
    "messages": [
      {"role": "user", "content": "Hello!"}
    ],
    "streaming": true
  }'
```

---

### 7. Get Models

L·∫•y danh s√°ch c√°c model Ollama c√≥ s·∫µn.

**Endpoint**: `GET /api/ollama/models`

**Tags**: `ollama`

**Response**:
- `200`: Tr·∫£ v·ªÅ danh s√°ch models

**Example cURL**:
```bash
curl -X GET "http://api.example.com/api/ollama/models"
```

---

## Health Check

### 8. Health Check

Ki·ªÉm tra tr·∫°ng th√°i ho·∫°t ƒë·ªông c·ªßa API.

**Endpoint**: `GET /api/health`

**Response**:
- `200`: API ƒëang ho·∫°t ƒë·ªông b√¨nh th∆∞·ªùng

**Example cURL**:
```bash
curl -X GET "http://api.example.com/api/health"
```


## Tham kh·∫£o
- [Tesseract ](https://github.com/UB-Mannheim/tesseract/wiki)
- [ChatGPT](https://chatgpt.com/c/69037dcc-49b0-8324-884c-23cfc09c95b6)